{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to DBMS Chapters Chapter 1: Introduction Chapter 2: Introduction to Relational Languages Chapter 3: Introduction to SQL Chapter 4: Intermediate SQL Chapter 5: Advanced SQL Sections 5.4 onwards may be omitted. Chapter 6: Entity-Relationship Model Chapter 7: Relational Database Design Chapter 8: Complex Data Types Chapter 9: Application Design Chapter 10: Big Data Chapter 11: Data Analytics Chapter 12: Physical Storage Systems Chapter 13: Storage and File Structure Chapter 14: Indexing Chapter 15: Query Processing Chapter 16: Query Optimization Chapter 17: Transactions Chapter 18: Concurrency Control Section 18.8 (Snapshot Isolation), Section 18.9 (Weak Levels of Consistency) may be omitted. Chapter 19: Recovery System Section 19.8 (ARIES) may be omitted. PostgreSQL Cheatsheet (Markdown) This cheatsheet summarizes some essential PostgreSQL commands for managing databases, users, tables, and data. Connection: psql -h <hostname> -p <port> -d <database> -U <username> : Connect to a PostgreSQL server (replace placeholders with actual values). Databases: CREATE DATABASE <database_name> : Create a new database. DROP DATABASE <database_name> : Delete an existing database (use with caution!). \\l : List all databases. \\connect <database_name> : Switch to a different database within the same session. Users and Roles: CREATE ROLE <username> [WITH PASSWORD '<password>'] : Create a new user. GRANT <privilege> ON <object> TO <username> : Grant specific privileges (e.g., SELECT, INSERT, UPDATE, DELETE) on a database object (table, schema) to a user. REVOKE <privilege> ON <object> FROM <username> : Revoke privileges from a user. \\du : List all roles (users). Tables: CREATE TABLE <table_name> ( <column_name> <data_type> [CONSTRAINT], ...); : Create a new table with columns and constraints. DESCRIBE <table_name> : Show the structure of a table. DROP TABLE <table_name> : Delete a table (use with caution!). \\dt : List all tables in the current schema. Data Manipulation: INSERT INTO <table_name> (<column1>, <column2>, ...) VALUES (<value1>, <value2>, ...); : Insert data into a table. SELECT * FROM <table_name> [WHERE <condition>]; : Retrieve data from a table (all columns by default, with optional filtering). UPDATE <table_name> SET <column_name> = <new_value> [WHERE <condition>]; : Update existing data in a table. DELETE FROM <table_name> [WHERE <condition>]; : Delete rows from a table. Other Useful Commands: \\q : Quit the psql client. \\h : Get help on a specific command (e.g., \\h CREATE TABLE ). \\conninfo : Display connection information. Additional Notes: Remember to replace placeholders like <database_name> , <username> , etc. with actual values. This is a basic cheatsheet. PostgreSQL offers many more commands and functionalities. Refer to the official documentation for in-depth details: https://www.postgresql.org/docs/","title":"Welcome to DBMS"},{"location":"#welcome-to-dbms","text":"","title":"Welcome to DBMS"},{"location":"#chapters","text":"Chapter 1: Introduction Chapter 2: Introduction to Relational Languages Chapter 3: Introduction to SQL Chapter 4: Intermediate SQL Chapter 5: Advanced SQL Sections 5.4 onwards may be omitted. Chapter 6: Entity-Relationship Model Chapter 7: Relational Database Design Chapter 8: Complex Data Types Chapter 9: Application Design Chapter 10: Big Data Chapter 11: Data Analytics Chapter 12: Physical Storage Systems Chapter 13: Storage and File Structure Chapter 14: Indexing Chapter 15: Query Processing Chapter 16: Query Optimization Chapter 17: Transactions Chapter 18: Concurrency Control Section 18.8 (Snapshot Isolation), Section 18.9 (Weak Levels of Consistency) may be omitted. Chapter 19: Recovery System Section 19.8 (ARIES) may be omitted.","title":"Chapters"},{"location":"#postgresql-cheatsheet-markdown","text":"This cheatsheet summarizes some essential PostgreSQL commands for managing databases, users, tables, and data. Connection: psql -h <hostname> -p <port> -d <database> -U <username> : Connect to a PostgreSQL server (replace placeholders with actual values). Databases: CREATE DATABASE <database_name> : Create a new database. DROP DATABASE <database_name> : Delete an existing database (use with caution!). \\l : List all databases. \\connect <database_name> : Switch to a different database within the same session. Users and Roles: CREATE ROLE <username> [WITH PASSWORD '<password>'] : Create a new user. GRANT <privilege> ON <object> TO <username> : Grant specific privileges (e.g., SELECT, INSERT, UPDATE, DELETE) on a database object (table, schema) to a user. REVOKE <privilege> ON <object> FROM <username> : Revoke privileges from a user. \\du : List all roles (users). Tables: CREATE TABLE <table_name> ( <column_name> <data_type> [CONSTRAINT], ...); : Create a new table with columns and constraints. DESCRIBE <table_name> : Show the structure of a table. DROP TABLE <table_name> : Delete a table (use with caution!). \\dt : List all tables in the current schema. Data Manipulation: INSERT INTO <table_name> (<column1>, <column2>, ...) VALUES (<value1>, <value2>, ...); : Insert data into a table. SELECT * FROM <table_name> [WHERE <condition>]; : Retrieve data from a table (all columns by default, with optional filtering). UPDATE <table_name> SET <column_name> = <new_value> [WHERE <condition>]; : Update existing data in a table. DELETE FROM <table_name> [WHERE <condition>]; : Delete rows from a table. Other Useful Commands: \\q : Quit the psql client. \\h : Get help on a specific command (e.g., \\h CREATE TABLE ). \\conninfo : Display connection information. Additional Notes: Remember to replace placeholders like <database_name> , <username> , etc. with actual values. This is a basic cheatsheet. PostgreSQL offers many more commands and functionalities. Refer to the official documentation for in-depth details: https://www.postgresql.org/docs/","title":"PostgreSQL Cheatsheet (Markdown)"},{"location":"cheatsheet/","text":"PSQL Magic words: psql -U postgres Some interesting flags (to see all, use -h or --help depending on your psql version): -E : will describe the underlaying queries of the \\ commands (cool for learning!) -l : psql will list all databases and then exit (useful if the user you connect with doesn't has a default database, like at AWS RDS) Most \\d commands support additional param of __schema__.name__ and accept wildcards like *.* \\? : Show help (list of available commands with an explanation) \\q : Quit/Exit \\c __database__ : Connect to a database \\d __table__ : Show table definition (columns, etc.) including triggers \\d+ __table__ : More detailed table definition including description and physical disk size \\l : List databases \\dy : List events \\df : List functions \\di : List indexes \\dn : List schemas \\dt *.* : List tables from all schemas (if *.* is omitted will only show SEARCH_PATH ones) \\dT+ : List all data types \\dv : List views \\dx : List all extensions installed \\df+ __function__ : Show function SQL code. \\x : Pretty-format query results instead of the not-so-useful ASCII tables \\copy (SELECT * FROM __table_name__) TO 'file_path_and_name.csv' WITH CSV : Export a table as CSV \\des+ : List all foreign servers \\dE[S+] : List all foreign tables \\! __bash_command__ : execute __bash_command__ (e.g. \\! ls ) User Related: \\du : List users \\du __username__ : List a username if present. create role __test1__ : Create a role with an existing username. create role __test2__ noinherit login password __passsword__; : Create a role with username and password. set role __test__; : Change role for current session to __test__ . grant __test2__ to __test1__; : Allow __test1__ to set its role as __test2__ . \\deu+ : List all user mapping on server Create command There are many CREATE choices, like CREATE DATABASE __database_name__ , CREATE TABLE __table_name__ ... Parameters differ but can be checked at the official documentation . Handy queries SELECT * FROM pg_proc WHERE proname='__procedurename__' : List procedure/function SELECT * FROM pg_views WHERE viewname='__viewname__'; : List view (including the definition) SELECT pg_size_pretty(pg_total_relation_size('__table_name__')); : Show DB table space in use SELECT pg_size_pretty(pg_database_size('__database_name__')); : Show DB space in use show statement_timeout; : Show current user's statement timeout SELECT * FROM pg_indexes WHERE tablename='__table_name__' AND schemaname='__schema_name__'; : Show table indexes Get all indexes from all tables of a schema: SELECT t . relname AS table_name , i . relname AS index_name , a . attname AS column_name FROM pg_class t , pg_class i , pg_index ix , pg_attribute a , pg_namespace n WHERE t . oid = ix . indrelid AND i . oid = ix . indexrelid AND a . attrelid = t . oid AND a . attnum = ANY ( ix . indkey ) AND t . relnamespace = n . oid AND n . nspname = 'kartones' ORDER BY t . relname , i . relname Execution data: Queries being executed at a certain DB: SELECT datname , application_name , pid , backend_start , query_start , state_change , state , query FROM pg_stat_activity WHERE datname = '__database_name__' ; Get all queries from all dbs waiting for data (might be hung): SELECT * FROM pg_stat_activity WHERE waiting = 't' Currently running queries with process pid: SELECT pg_stat_get_backend_pid ( s . backendid ) AS procpid , pg_stat_get_backend_activity ( s . backendid ) AS current_query FROM ( SELECT pg_stat_get_backend_idset () AS backendid ) AS s ; Get Connections by Database: SELECT datname, numbackends FROM pg_stat_database; Casting: CAST (column AS type) or column::type '__table_name__'::regclass::oid : Get oid having a table name Query analysis: EXPLAIN __query__ : see the query plan for the given query EXPLAIN ANALYZE __query__ : see and execute the query plan for the given query ANALYZE [__table__] : collect statistics Generating random data ( source ): INSERT INTO some_table (a_float_value) SELECT random() * 100000 FROM generate_series(1, 1000000) i; Get sizes of tables, indexes and full DBs: select current_database () as database , pg_size_pretty ( total_database_size ) as total_database_size , schema_name , table_name , pg_size_pretty ( total_table_size ) as total_table_size , pg_size_pretty ( table_size ) as table_size , pg_size_pretty ( index_size ) as index_size from ( select table_name , table_schema as schema_name , pg_database_size ( current_database ()) as total_database_size , pg_total_relation_size ( table_name ) as total_table_size , pg_relation_size ( table_name ) as table_size , pg_indexes_size ( table_name ) as index_size from information_schema . tables where table_schema = current_schema () and table_name like 'table_%' order by total_table_size ) as sizes ; COPY command : Import/export from CSV to tables: COPY table_name [ ( column_name [, ...] ) ] FROM { 'filename' | STDIN } [ [ WITH ] ( option [, ...] ) ] COPY { table_name [ ( column_name [, ...] ) ] | ( query ) } TO { 'filename' | STDOUT } [ [ WITH ] ( option [, ...] ) ] List all grants for a specific user SELECT table_catalog , table_schema , table_name , privilege_type FROM information_schema . table_privileges WHERE grantee = 'user_to_check' ORDER BY table_name ; List all assigned user roles SELECT r . rolname , r . rolsuper , r . rolinherit , r . rolcreaterole , r . rolcreatedb , r . rolcanlogin , r . rolconnlimit , r . rolvaliduntil , ARRAY ( SELECT b . rolname FROM pg_catalog . pg_auth_members m JOIN pg_catalog . pg_roles b ON ( m . roleid = b . oid ) WHERE m . member = r . oid ) as memberof , r . rolreplication FROM pg_catalog . pg_roles r ORDER BY 1 ; Check permissions in a table: SELECT grantee , privilege_type FROM information_schema . role_table_grants WHERE table_name = 'name-of-the-table' ; Kill all Connections: SELECT pg_terminate_backend ( pg_stat_activity . pid ) FROM pg_stat_activity WHERE datname = current_database () AND pid <> pg_backend_pid (); Keyboard shortcuts CTRL + R : reverse-i-search Tools ptop and pg_top : top for PG. Available on the APT repository from apt.postgresql.org . pg_activity : Command line tool for PostgreSQL server activity monitoring. Unix-like reverse search in psql : $ echo \"bind \" ^R \" em-inc-search-prev\" > $HOME /.editrc $ source $HOME /.editrc Show IP of the DB Instance: SELECT inet_server_addr(); File to save PostgreSQL credentials and permissions (format: hostname:port:database:username:password ): chmod 600 ~/.pgpass Collect statistics of a database (useful to improve speed after a Database Upgrade as previous query plans are deleted): ANALYZE VERBOSE; To obtain the CREATE TABLE query of a table, any visual GUI like pgAdmin allows to easily, but else you can use pg_dump , e.g.: pg_dump -t '<schema>.<table>' --schema-only <database> ( source ) Resources & Documentation Operations Cheat Sheet : Official PG wiki cheat sheet with an amazing amount of explanations of many topics, features, and many many internal implementation details Postgres Weekly newsletter: The best way IMHO to keep up to date with PG news 100 psql Tips : Name says all, lots of useful tips! PostgreSQL Exercises : An awesome resource to learn to learn SQL, teaching you with simple examples in a great visual way. Highly recommended . A Performance Cheat Sheet for PostgreSQL : Great explanations of EXPLAIN , EXPLAIN ANALYZE , VACUUM , configuration parameters and more. Quite interesting if you need to tune-up a postgres setup. annotated.conf : Annotations of all 269 postgresql.conf settings for PostgreSQL 10. psql -c \"\\l+\" -H -q postgres > out.html : Generate a html report of your databases (source: Daniel Westermann ) </pre>","title":"Cheatsheet"},{"location":"cheatsheet/#psql","text":"Magic words: psql -U postgres Some interesting flags (to see all, use -h or --help depending on your psql version): -E : will describe the underlaying queries of the \\ commands (cool for learning!) -l : psql will list all databases and then exit (useful if the user you connect with doesn't has a default database, like at AWS RDS) Most \\d commands support additional param of __schema__.name__ and accept wildcards like *.* \\? : Show help (list of available commands with an explanation) \\q : Quit/Exit \\c __database__ : Connect to a database \\d __table__ : Show table definition (columns, etc.) including triggers \\d+ __table__ : More detailed table definition including description and physical disk size \\l : List databases \\dy : List events \\df : List functions \\di : List indexes \\dn : List schemas \\dt *.* : List tables from all schemas (if *.* is omitted will only show SEARCH_PATH ones) \\dT+ : List all data types \\dv : List views \\dx : List all extensions installed \\df+ __function__ : Show function SQL code. \\x : Pretty-format query results instead of the not-so-useful ASCII tables \\copy (SELECT * FROM __table_name__) TO 'file_path_and_name.csv' WITH CSV : Export a table as CSV \\des+ : List all foreign servers \\dE[S+] : List all foreign tables \\! __bash_command__ : execute __bash_command__ (e.g. \\! ls ) User Related: \\du : List users \\du __username__ : List a username if present. create role __test1__ : Create a role with an existing username. create role __test2__ noinherit login password __passsword__; : Create a role with username and password. set role __test__; : Change role for current session to __test__ . grant __test2__ to __test1__; : Allow __test1__ to set its role as __test2__ . \\deu+ : List all user mapping on server","title":"PSQL"},{"location":"cheatsheet/#create-command","text":"There are many CREATE choices, like CREATE DATABASE __database_name__ , CREATE TABLE __table_name__ ... Parameters differ but can be checked at the official documentation .","title":"Create command"},{"location":"cheatsheet/#handy-queries","text":"SELECT * FROM pg_proc WHERE proname='__procedurename__' : List procedure/function SELECT * FROM pg_views WHERE viewname='__viewname__'; : List view (including the definition) SELECT pg_size_pretty(pg_total_relation_size('__table_name__')); : Show DB table space in use SELECT pg_size_pretty(pg_database_size('__database_name__')); : Show DB space in use show statement_timeout; : Show current user's statement timeout SELECT * FROM pg_indexes WHERE tablename='__table_name__' AND schemaname='__schema_name__'; : Show table indexes Get all indexes from all tables of a schema: SELECT t . relname AS table_name , i . relname AS index_name , a . attname AS column_name FROM pg_class t , pg_class i , pg_index ix , pg_attribute a , pg_namespace n WHERE t . oid = ix . indrelid AND i . oid = ix . indexrelid AND a . attrelid = t . oid AND a . attnum = ANY ( ix . indkey ) AND t . relnamespace = n . oid AND n . nspname = 'kartones' ORDER BY t . relname , i . relname Execution data: Queries being executed at a certain DB: SELECT datname , application_name , pid , backend_start , query_start , state_change , state , query FROM pg_stat_activity WHERE datname = '__database_name__' ; Get all queries from all dbs waiting for data (might be hung): SELECT * FROM pg_stat_activity WHERE waiting = 't' Currently running queries with process pid: SELECT pg_stat_get_backend_pid ( s . backendid ) AS procpid , pg_stat_get_backend_activity ( s . backendid ) AS current_query FROM ( SELECT pg_stat_get_backend_idset () AS backendid ) AS s ; Get Connections by Database: SELECT datname, numbackends FROM pg_stat_database; Casting: CAST (column AS type) or column::type '__table_name__'::regclass::oid : Get oid having a table name Query analysis: EXPLAIN __query__ : see the query plan for the given query EXPLAIN ANALYZE __query__ : see and execute the query plan for the given query ANALYZE [__table__] : collect statistics Generating random data ( source ): INSERT INTO some_table (a_float_value) SELECT random() * 100000 FROM generate_series(1, 1000000) i; Get sizes of tables, indexes and full DBs: select current_database () as database , pg_size_pretty ( total_database_size ) as total_database_size , schema_name , table_name , pg_size_pretty ( total_table_size ) as total_table_size , pg_size_pretty ( table_size ) as table_size , pg_size_pretty ( index_size ) as index_size from ( select table_name , table_schema as schema_name , pg_database_size ( current_database ()) as total_database_size , pg_total_relation_size ( table_name ) as total_table_size , pg_relation_size ( table_name ) as table_size , pg_indexes_size ( table_name ) as index_size from information_schema . tables where table_schema = current_schema () and table_name like 'table_%' order by total_table_size ) as sizes ; COPY command : Import/export from CSV to tables: COPY table_name [ ( column_name [, ...] ) ] FROM { 'filename' | STDIN } [ [ WITH ] ( option [, ...] ) ] COPY { table_name [ ( column_name [, ...] ) ] | ( query ) } TO { 'filename' | STDOUT } [ [ WITH ] ( option [, ...] ) ] List all grants for a specific user SELECT table_catalog , table_schema , table_name , privilege_type FROM information_schema . table_privileges WHERE grantee = 'user_to_check' ORDER BY table_name ; List all assigned user roles SELECT r . rolname , r . rolsuper , r . rolinherit , r . rolcreaterole , r . rolcreatedb , r . rolcanlogin , r . rolconnlimit , r . rolvaliduntil , ARRAY ( SELECT b . rolname FROM pg_catalog . pg_auth_members m JOIN pg_catalog . pg_roles b ON ( m . roleid = b . oid ) WHERE m . member = r . oid ) as memberof , r . rolreplication FROM pg_catalog . pg_roles r ORDER BY 1 ; Check permissions in a table: SELECT grantee , privilege_type FROM information_schema . role_table_grants WHERE table_name = 'name-of-the-table' ; Kill all Connections: SELECT pg_terminate_backend ( pg_stat_activity . pid ) FROM pg_stat_activity WHERE datname = current_database () AND pid <> pg_backend_pid ();","title":"Handy queries"},{"location":"cheatsheet/#keyboard-shortcuts","text":"CTRL + R : reverse-i-search","title":"Keyboard shortcuts"},{"location":"cheatsheet/#tools","text":"ptop and pg_top : top for PG. Available on the APT repository from apt.postgresql.org . pg_activity : Command line tool for PostgreSQL server activity monitoring. Unix-like reverse search in psql : $ echo \"bind \" ^R \" em-inc-search-prev\" > $HOME /.editrc $ source $HOME /.editrc Show IP of the DB Instance: SELECT inet_server_addr(); File to save PostgreSQL credentials and permissions (format: hostname:port:database:username:password ): chmod 600 ~/.pgpass Collect statistics of a database (useful to improve speed after a Database Upgrade as previous query plans are deleted): ANALYZE VERBOSE; To obtain the CREATE TABLE query of a table, any visual GUI like pgAdmin allows to easily, but else you can use pg_dump , e.g.: pg_dump -t '<schema>.<table>' --schema-only <database> ( source )","title":"Tools"},{"location":"cheatsheet/#resources-documentation","text":"Operations Cheat Sheet : Official PG wiki cheat sheet with an amazing amount of explanations of many topics, features, and many many internal implementation details Postgres Weekly newsletter: The best way IMHO to keep up to date with PG news 100 psql Tips : Name says all, lots of useful tips! PostgreSQL Exercises : An awesome resource to learn to learn SQL, teaching you with simple examples in a great visual way. Highly recommended . A Performance Cheat Sheet for PostgreSQL : Great explanations of EXPLAIN , EXPLAIN ANALYZE , VACUUM , configuration parameters and more. Quite interesting if you need to tune-up a postgres setup. annotated.conf : Annotations of all 269 postgresql.conf settings for PostgreSQL 10. psql -c \"\\l+\" -H -q postgres > out.html : Generate a html report of your databases (source: Daniel Westermann ) </pre>","title":"Resources &amp; Documentation"},{"location":"Week%205/Lecture%205.1%20-%20Relational%20Database%20Design1/","text":"Lecture 5.1 - Relational Database Design1 Summary This module focuses on principles of relational database design. It emphasizes: Features of Good Design: Reflects real-world structure Accommodates future data additions Avoids redundancy Provides efficient data access Maintains data integrity Redundancy and Anomaly: Redundancy (duplicate data) leads to anomalies: Insertion: Can't add data if unknown data is required Deletion: Losing unrelated information when deleting records Update: Inaccurate changes due to multiple occurrences of data Decomposition: Decomposing relations into smaller ones removes redundancy and minimizes dependencies among attributes. Good decomposition ensures data preservation and integrity. functional dependency : dept name \u2192 building, budget In inst_dept, because dept_name is not a candidate key, the building and budget of a department may have to be repeated. \u25e6 This indicates the need to decompose inst dept Lossy Decomposition Lossless Join Decomposition is a decomposition of a relation R into relations R1 , R2 such that if we perform natural join of two smaller relations it will return the original relation Atomic Domains and First Normal Form (1NF): Atomic domains consist of indivisible elements. 1NF requires relations with atomic domains and each attribute holding a single value. Non-atomic values complicate storage and encourage redundancy. Atomic Domains An atomic domain refers to the indivisibility of data within a domain. In the context of databases, it means that the value in a particular field is indivisible and represents the smallest unit of data. Each attribute in a table should contain atomic (indivisible) values. Example of Atomic Values : 123 Main St , John Doe , 01/01/2020 Example of Non-Atomic Values : 123 Main St, Apt 4 (multiple pieces of information in one field) John and Jane Doe (multiple names in one field) First Normal Form (1NF) A relation (table) is said to be in the First Normal Form (1NF) if it satisfies the following conditions: Atomicity : All the values in the database are atomic (indivisible). Uniqueness of Rows : Each row in the table must be unique, meaning no two rows can be identical. Uniqueness of Column Names : Each column should have a unique name. No Repeating Groups : Each table should contain only one value per cell (intersection of a row and a column), and columns should not contain sets or lists of values. Examples of 1NF Non-1NF Table: StudentID Name Courses 1 John Doe Math, Science 2 Jane Smith English, History, Math In the above table: The Courses column contains multiple values, which violates the atomicity rule. 1NF Table: StudentID Name Course 1 John Doe Math 1 John Doe Science 2 Jane Smith English 2 Jane Smith History 2 Jane Smith Math In this 1NF table: Each cell contains only one value, adhering to the atomicity requirement. Each row is unique, and there are no repeating groups within any cell. Achieving 1NF To transform a table into 1NF: Remove Repeating Groups : Ensure that each column contains only a single value. Create Separate Tables for Multivalued Attributes : If necessary, split the multivalued attributes into separate rows or tables. Ensure Primary Keys : Define primary keys to uniquely identify each row in the table. By adhering to these principles, a database can be designed to comply with the First Normal Form, thus ensuring data integrity and facilitating easier querying and maintenance.","title":"Lecture 5.1 - Relational Database Design1"},{"location":"Week%205/Lecture%205.1%20-%20Relational%20Database%20Design1/#lecture-51-relational-database-design1","text":"Summary This module focuses on principles of relational database design. It emphasizes: Features of Good Design: Reflects real-world structure Accommodates future data additions Avoids redundancy Provides efficient data access Maintains data integrity Redundancy and Anomaly: Redundancy (duplicate data) leads to anomalies: Insertion: Can't add data if unknown data is required Deletion: Losing unrelated information when deleting records Update: Inaccurate changes due to multiple occurrences of data Decomposition: Decomposing relations into smaller ones removes redundancy and minimizes dependencies among attributes. Good decomposition ensures data preservation and integrity. functional dependency : dept name \u2192 building, budget In inst_dept, because dept_name is not a candidate key, the building and budget of a department may have to be repeated. \u25e6 This indicates the need to decompose inst dept Lossy Decomposition Lossless Join Decomposition is a decomposition of a relation R into relations R1 , R2 such that if we perform natural join of two smaller relations it will return the original relation Atomic Domains and First Normal Form (1NF): Atomic domains consist of indivisible elements. 1NF requires relations with atomic domains and each attribute holding a single value. Non-atomic values complicate storage and encourage redundancy. Atomic Domains An atomic domain refers to the indivisibility of data within a domain. In the context of databases, it means that the value in a particular field is indivisible and represents the smallest unit of data. Each attribute in a table should contain atomic (indivisible) values. Example of Atomic Values : 123 Main St , John Doe , 01/01/2020 Example of Non-Atomic Values : 123 Main St, Apt 4 (multiple pieces of information in one field) John and Jane Doe (multiple names in one field)","title":"Lecture 5.1 - Relational Database Design1"},{"location":"Week%205/Lecture%205.1%20-%20Relational%20Database%20Design1/#first-normal-form-1nf","text":"A relation (table) is said to be in the First Normal Form (1NF) if it satisfies the following conditions: Atomicity : All the values in the database are atomic (indivisible). Uniqueness of Rows : Each row in the table must be unique, meaning no two rows can be identical. Uniqueness of Column Names : Each column should have a unique name. No Repeating Groups : Each table should contain only one value per cell (intersection of a row and a column), and columns should not contain sets or lists of values.","title":"First Normal Form (1NF)"},{"location":"Week%205/Lecture%205.1%20-%20Relational%20Database%20Design1/#examples-of-1nf","text":"Non-1NF Table: StudentID Name Courses 1 John Doe Math, Science 2 Jane Smith English, History, Math In the above table: The Courses column contains multiple values, which violates the atomicity rule. 1NF Table: StudentID Name Course 1 John Doe Math 1 John Doe Science 2 Jane Smith English 2 Jane Smith History 2 Jane Smith Math In this 1NF table: Each cell contains only one value, adhering to the atomicity requirement. Each row is unique, and there are no repeating groups within any cell.","title":"Examples of 1NF"},{"location":"Week%205/Lecture%205.1%20-%20Relational%20Database%20Design1/#achieving-1nf","text":"To transform a table into 1NF: Remove Repeating Groups : Ensure that each column contains only a single value. Create Separate Tables for Multivalued Attributes : If necessary, split the multivalued attributes into separate rows or tables. Ensure Primary Keys : Define primary keys to uniquely identify each row in the table. By adhering to these principles, a database can be designed to comply with the First Normal Form, thus ensuring data integrity and facilitating easier querying and maintenance.","title":"Achieving 1NF"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/","text":"Lecture 5.2: Relational Database Design Functional Dependencies Definition Constraints on the set of legal relations. Require that the value for a certain set of attributes determines uniquely the value for another set of attributes. A generalization of the notion of a key. Formal Definition For a relation schema \\( R \\) , \\( $\\alpha \\subseteq R$ \\) and \\( $\\beta \\subseteq R $\\) . The functional dependency ( $\\alpha \\to \\beta $) holds on \\( R \\) if for any legal relations \\( r(R) \\) , whenever any two tuples \\( $t_1$ \\) and \\( $t_2$ \\) of \\( $r$ \\) agree on the attributes \\( $ \\alpha $ \\) , they also agree on the attributes \\( $\\beta$ \\) . Example: \\( $A \\to B$ \\) does not hold, but \\( $B \\to A$ \\) holds for a certain instance. Keys Superkey: \\( $K$ \\) is a superkey for relation schema \\( $R$ \\) if and only if ($ K \\to R \\ $). Candidate Key: \\( K \\) is a candidate key for \\( R \\) if and only if \\( $K \\to R$ \\) and for no \\($\\alpha \\subset K $\\) , \\( $\\alpha \\to R $\\) . Practical Examples Schema: inst_dept(ID, name, salary, dept_name, building, budget) Expected FDs: dept_name \u2192 building dept_name \u2192 budget ID \u2192 budget Unexpected FD: dept_name \u2192 salary Trivial Functional Dependencies A functional dependency is trivial if it is satisfied by all instances of a relation. Example: \\( $\\text{ID, name} \\to \\text{ID} $\\) and \\( $\\text{name} \\to \\text{name} $\\) . Generally, \\( $\\alpha \\to \\beta $ \\) is trivial if \\( $\\beta \\subseteq \\alpha $\\) . Armstrong\u2019s Axioms Definition Given a set of FDs \\( F \\) , infer new dependencies using: Reflexivity: If \\( $\\beta \\subseteq \\alpha$ \\) , then \\( \\alpha \\to \\beta \\) . Augmentation: If \\( $\\alpha \\to \\beta $ \\) , then \\( $\\gamma\\alpha \\to \\gamma\\beta $\\) . Transitivity: If \\( $\\alpha \\to \\beta $\\) and \\( $\\beta \\to \\gamma $\\) , then \\( $\\alpha \\to \\gamma $\\) . Closure The closure of a set of FDs \\( $F$ \\) is the set \\( $F^+ $\\) of all FDs logically implied by \\( F \\) . Example: \\( $F = \\{ A \\to B, B \\to C \\}$ \\) \\( $F^+ = \\{ A \\to B, B \\to C, A \\to C \\} $\\) Properties Axioms are sound (generate only FDs that hold) and complete (generate all FDs that hold). Module Summary Introduced the notion of Functional Dependencies. Explained Armstrong\u2019s Axioms and their application to infer new FDs. Discussed the concept of the closure of a set of FDs.","title":"Lecture 5.2: Relational Database Design"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#lecture-52-relational-database-design","text":"","title":"Lecture 5.2: Relational Database Design"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#functional-dependencies","text":"","title":"Functional Dependencies"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#definition","text":"Constraints on the set of legal relations. Require that the value for a certain set of attributes determines uniquely the value for another set of attributes. A generalization of the notion of a key.","title":"Definition"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#formal-definition","text":"For a relation schema \\( R \\) , \\( $\\alpha \\subseteq R$ \\) and \\( $\\beta \\subseteq R $\\) . The functional dependency ( $\\alpha \\to \\beta $) holds on \\( R \\) if for any legal relations \\( r(R) \\) , whenever any two tuples \\( $t_1$ \\) and \\( $t_2$ \\) of \\( $r$ \\) agree on the attributes \\( $ \\alpha $ \\) , they also agree on the attributes \\( $\\beta$ \\) . Example: \\( $A \\to B$ \\) does not hold, but \\( $B \\to A$ \\) holds for a certain instance.","title":"Formal Definition"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#keys","text":"Superkey: \\( $K$ \\) is a superkey for relation schema \\( $R$ \\) if and only if ($ K \\to R \\ $). Candidate Key: \\( K \\) is a candidate key for \\( R \\) if and only if \\( $K \\to R$ \\) and for no \\($\\alpha \\subset K $\\) , \\( $\\alpha \\to R $\\) .","title":"Keys"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#practical-examples","text":"Schema: inst_dept(ID, name, salary, dept_name, building, budget) Expected FDs: dept_name \u2192 building dept_name \u2192 budget ID \u2192 budget Unexpected FD: dept_name \u2192 salary","title":"Practical Examples"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#trivial-functional-dependencies","text":"A functional dependency is trivial if it is satisfied by all instances of a relation. Example: \\( $\\text{ID, name} \\to \\text{ID} $\\) and \\( $\\text{name} \\to \\text{name} $\\) . Generally, \\( $\\alpha \\to \\beta $ \\) is trivial if \\( $\\beta \\subseteq \\alpha $\\) .","title":"Trivial Functional Dependencies"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#armstrongs-axioms","text":"","title":"Armstrong\u2019s Axioms"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#definition_1","text":"Given a set of FDs \\( F \\) , infer new dependencies using: Reflexivity: If \\( $\\beta \\subseteq \\alpha$ \\) , then \\( \\alpha \\to \\beta \\) . Augmentation: If \\( $\\alpha \\to \\beta $ \\) , then \\( $\\gamma\\alpha \\to \\gamma\\beta $\\) . Transitivity: If \\( $\\alpha \\to \\beta $\\) and \\( $\\beta \\to \\gamma $\\) , then \\( $\\alpha \\to \\gamma $\\) .","title":"Definition"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#closure","text":"The closure of a set of FDs \\( $F$ \\) is the set \\( $F^+ $\\) of all FDs logically implied by \\( F \\) . Example: \\( $F = \\{ A \\to B, B \\to C \\}$ \\) \\( $F^+ = \\{ A \\to B, B \\to C, A \\to C \\} $\\)","title":"Closure"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#properties","text":"Axioms are sound (generate only FDs that hold) and complete (generate all FDs that hold).","title":"Properties"},{"location":"Week%205/Lecture%205.2%20-%20Relational%20Database%20Design2/#module-summary","text":"Introduced the notion of Functional Dependencies. Explained Armstrong\u2019s Axioms and their application to infer new FDs. Discussed the concept of the closure of a set of FDs.","title":"Module Summary"},{"location":"Week%205/Lecture%205.3%20-%20Relational%20Database%20Design3/","text":"Lecture 5.3 - Relational Database Design 3 Summary This module discusses relational database design using functional dependencies (FDs). FD Theory: Armstrong's Axioms are used to derive new FDs from a given set. Closure of FDs generates all FDs logically implied by a set. Closure of attributes determines the attributes functionally determined by a set of attributes. Decomposition Using FDs: Boyce-Codd Normal Form (BCNF) ensures that non-trivial FDs involve superkeys or attributes in candidate keys. Decomposing relations into BCNF guarantees lossless join but may not preserve dependencies. 3NF (Third Normal Form): Relaxes BCNF by allowing attributes in candidate keys but enforces dependency preservation. Normalization Goals: Evaluate relation schemes for \"good\" form. Decompose schemes into lossless-join and dependency-preserving relations. Problems with Decomposition: Potential lossiness, dependency checking issues, and query performance concerns exist. Limitations of BCNF: BCNF may not prevent insertion anomalies in certain scenarios, suggesting the need for higher normal forms like 4NF.","title":"Lecture 5.3 - Relational Database Design 3"},{"location":"Week%205/Lecture%205.3%20-%20Relational%20Database%20Design3/#lecture-53-relational-database-design-3","text":"Summary This module discusses relational database design using functional dependencies (FDs). FD Theory: Armstrong's Axioms are used to derive new FDs from a given set. Closure of FDs generates all FDs logically implied by a set. Closure of attributes determines the attributes functionally determined by a set of attributes. Decomposition Using FDs: Boyce-Codd Normal Form (BCNF) ensures that non-trivial FDs involve superkeys or attributes in candidate keys. Decomposing relations into BCNF guarantees lossless join but may not preserve dependencies. 3NF (Third Normal Form): Relaxes BCNF by allowing attributes in candidate keys but enforces dependency preservation. Normalization Goals: Evaluate relation schemes for \"good\" form. Decompose schemes into lossless-join and dependency-preserving relations. Problems with Decomposition: Potential lossiness, dependency checking issues, and query performance concerns exist. Limitations of BCNF: BCNF may not prevent insertion anomalies in certain scenarios, suggesting the need for higher normal forms like 4NF.","title":"Lecture 5.3 - Relational Database Design 3"},{"location":"Week%205/Lecture%205.4%20-%20Relational%20Database%20Design4/","text":"Lecture 5.4 - Relational Database Design Summary This module covers algorithms and properties related to functional dependencies (FDs). Attribute Set Closure: Algorithm to find the closure of an attribute set, which includes the set itself and all attributes implied by FDs. Used to test if an attribute set is a superkey or to test functional dependencies. Extraneous Attributes: Algorithms to identify and remove extraneous attributes, which are redundant in FDs. Helps optimize the set of FDs by eliminating unnecessary dependencies. Equivalence of FD Sets: Two sets of FDs are equivalent if they logically imply each other's dependencies. Useful for comparing different representations of functional dependencies. Canonical Cover: Algorithm to find a minimal and unique set of FDs that represent a given set of FDs. Ensures that there are no redundant or extraneous dependencies. The canonical cover is often used as a \"normalized\" representation of functional dependencies. Practice Problems: Exercises to test understanding of the algorithms and concepts discussed. Cover tasks like checking FD implications, finding super and candidate keys, and computing canonical covers.","title":"Lecture 5.4 - Relational Database Design"},{"location":"Week%205/Lecture%205.4%20-%20Relational%20Database%20Design4/#lecture-54-relational-database-design","text":"Summary This module covers algorithms and properties related to functional dependencies (FDs). Attribute Set Closure: Algorithm to find the closure of an attribute set, which includes the set itself and all attributes implied by FDs. Used to test if an attribute set is a superkey or to test functional dependencies. Extraneous Attributes: Algorithms to identify and remove extraneous attributes, which are redundant in FDs. Helps optimize the set of FDs by eliminating unnecessary dependencies. Equivalence of FD Sets: Two sets of FDs are equivalent if they logically imply each other's dependencies. Useful for comparing different representations of functional dependencies. Canonical Cover: Algorithm to find a minimal and unique set of FDs that represent a given set of FDs. Ensures that there are no redundant or extraneous dependencies. The canonical cover is often used as a \"normalized\" representation of functional dependencies. Practice Problems: Exercises to test understanding of the algorithms and concepts discussed. Cover tasks like checking FD implications, finding super and candidate keys, and computing canonical covers.","title":"Lecture 5.4 - Relational Database Design"},{"location":"Week%205/Lecture%205.5%20-%20Relational%20Database%20Design5/","text":"Lecture 5.5 - Relational Database Design5.pdf (PDF file) Summary Relational Database Design Lossless Join Decomposition A decomposition of a relation R into R1 and R2 is lossless if either R1 \u2229 R2 \u2192 R1 or R1 \u2229 R2 \u2192 R2 is in the set of functional dependencies (FDs) for R. This condition ensures that the original relation can be reconstructed by joining R1 and R2. Dependency Preservation A decomposition of R into D = {R1, R2, ..., Rn} is dependency preserving if (F1 \u222a F2 \u222a ... \u222a Fn) = F, where: Fi is the set of FDs including attributes only in Ri This ensures that all FDs in F are preserved in the decomposition. Testing Dependency Preservation Test if a dependency \u03b1 \u2192 \u03b2 is preserved by: Computing F0 = F1 \u222a F2 \u222a ... \u222a Fn Check if \u03b2 is in the attribute closure of \u03b1 with respect to F0 Practice Problems Lossless Join Decomposition Determine if the following decompositions are lossless: R(ABC) : F = {A \u2192 B, A \u2192 C} \u2192 {R1(AB), R2(BC)} R(ABCDEF) : F = {A \u2192 B, B \u2192 C, C \u2192 D, E \u2192 F} \u2192 {R1(AB), R2(BCD), R3(DEF)} R(ABCDEF) : F = {A \u2192 B, C \u2192 DE, AC \u2192 F} \u2192 {R1(BE), R2(ACDEF)} R(ABCDEG) : F = {AB \u2192 C, AC \u2192 B, AD \u2192 E, B \u2192 D, BC \u2192 A, E \u2192 G} \u2192 {R1(AB), R2(BC), R3(ABDE), R4(EG)} R(ABCDEFGHIJ) : F = {AB \u2192 C, B \u2192 F, D \u2192 IJ, A \u2192 DE, F \u2192 GH} \u2192 {R1(ABC), R2(ADE), R3(BF), R4(FGH), R5(DIJ)} Dependency Preservation Verify if the following decompositions preserve dependencies: R(ABCD) : F = {A \u2192 B, B \u2192 C, C \u2192 D, D \u2192 A} \u2192 {AB, BC, CD} R(ABCDEF) : F = {AB \u2192 CD, C \u2192 D, D \u2192 E, E \u2192 F} \u2192 {AB, CDE, EF} R(ABCDEG) : F = {AB \u2192 C, AC \u2192 B, BC \u2192 A, AD \u2192 E, B \u2192 D, E \u2192 G} \u2192 {ABC, ACDE, ADG} R(ABCD) : F = {A \u2192 B, B \u2192 C, C \u2192 D, D \u2192 B} \u2192 {AB, BC, BD} R(ABCDE) : F = {A \u2192 BC, CD \u2192 E, B \u2192 D, E \u2192 A} \u2192 {ABCE, BD}","title":"Lecture 5.5 - Relational Database Design5.pdf (PDF file)"},{"location":"Week%205/Lecture%205.5%20-%20Relational%20Database%20Design5/#lecture-55-relational-database-design5pdf-pdf-file","text":"Summary Relational Database Design Lossless Join Decomposition A decomposition of a relation R into R1 and R2 is lossless if either R1 \u2229 R2 \u2192 R1 or R1 \u2229 R2 \u2192 R2 is in the set of functional dependencies (FDs) for R. This condition ensures that the original relation can be reconstructed by joining R1 and R2. Dependency Preservation A decomposition of R into D = {R1, R2, ..., Rn} is dependency preserving if (F1 \u222a F2 \u222a ... \u222a Fn) = F, where: Fi is the set of FDs including attributes only in Ri This ensures that all FDs in F are preserved in the decomposition. Testing Dependency Preservation Test if a dependency \u03b1 \u2192 \u03b2 is preserved by: Computing F0 = F1 \u222a F2 \u222a ... \u222a Fn Check if \u03b2 is in the attribute closure of \u03b1 with respect to F0 Practice Problems Lossless Join Decomposition Determine if the following decompositions are lossless: R(ABC) : F = {A \u2192 B, A \u2192 C} \u2192 {R1(AB), R2(BC)} R(ABCDEF) : F = {A \u2192 B, B \u2192 C, C \u2192 D, E \u2192 F} \u2192 {R1(AB), R2(BCD), R3(DEF)} R(ABCDEF) : F = {A \u2192 B, C \u2192 DE, AC \u2192 F} \u2192 {R1(BE), R2(ACDEF)} R(ABCDEG) : F = {AB \u2192 C, AC \u2192 B, AD \u2192 E, B \u2192 D, BC \u2192 A, E \u2192 G} \u2192 {R1(AB), R2(BC), R3(ABDE), R4(EG)} R(ABCDEFGHIJ) : F = {AB \u2192 C, B \u2192 F, D \u2192 IJ, A \u2192 DE, F \u2192 GH} \u2192 {R1(ABC), R2(ADE), R3(BF), R4(FGH), R5(DIJ)} Dependency Preservation Verify if the following decompositions preserve dependencies: R(ABCD) : F = {A \u2192 B, B \u2192 C, C \u2192 D, D \u2192 A} \u2192 {AB, BC, CD} R(ABCDEF) : F = {AB \u2192 CD, C \u2192 D, D \u2192 E, E \u2192 F} \u2192 {AB, CDE, EF} R(ABCDEG) : F = {AB \u2192 C, AC \u2192 B, BC \u2192 A, AD \u2192 E, B \u2192 D, E \u2192 G} \u2192 {ABC, ACDE, ADG} R(ABCD) : F = {A \u2192 B, B \u2192 C, C \u2192 D, D \u2192 B} \u2192 {AB, BC, BD} R(ABCDE) : F = {A \u2192 BC, CD \u2192 E, B \u2192 D, E \u2192 A} \u2192 {ABCE, BD}","title":"Lecture 5.5 - Relational Database Design5.pdf (PDF file)"},{"location":"Week%205/closureofartibut/","text":"(AC)^plus = 1. as A-> B (AC)^+ = ACB 2. as BC -> DE (AC)^+ = ACBDE 3. AEF -> G and F not in (AC)^+ 4. (AC)^+ = \"ACBDE\" 1. closure if ACF as A -> B ACF + = ACFB 2. BC -> DE ACF + = ACFBDE 3. AEF -> G ACF + = ACFBDEG","title":"Closureofartibut"},{"location":"arifacts/Lecture%201.4%20-%20Intro%20to%20DBMS1_annotated/","text":"","title":"Lecture 1.4   Intro to DBMS1 annotated"},{"location":"arifacts/Lecture%202.1%20-%20Introduction%20to%20Relational%20Model1_annotated/","text":"","title":"Lecture 2.1   Introduction to Relational Model1 annotated"},{"location":"arifacts/Lecture%202.2%20-%20Introduction%20to%20Relational%20Model2_annotated/","text":"","title":"Lecture 2.2   Introduction to Relational Model2 annotated"},{"location":"arifacts/Lecture%202.3%20-%20Introduction%20to%20SQL1_annotated/","text":"","title":"Lecture 2.3   Introduction to SQL1 annotated"},{"location":"arifacts/Lecture%202.4%20-%20Introduction%20to%20SQL2_annotated/","text":"","title":"Lecture 2.4   Introduction to SQL2 annotated"},{"location":"arifacts/Lecture%202.5%20-%20Introduction%20to%20SQL3_annotated/","text":"","title":"Lecture 2.5   Introduction to SQL3 annotated"},{"location":"week1/Lecture%201.1%20-%20Course%20Overview/","text":"Lecture 1.1 - Course Overview.pdf (PDF file) Summary Database Management Systems (DBMSs) are crucial in modern applications, providing organized access to large volumes of interconnected data through a user-friendly interface. They offer advantages such as eliminating data redundancy, enhancing data accessibility, promoting data security, and ensuring data integrity. This course provides an overview of DBMS concepts and applications, including fundamental sets, relations, functions, propositional and predicate logic, data structures, object-oriented analysis, and Python programming. The essential prerequisites for the course include set theory, relations and functions, propositional logic, predicate logic, data structures, programming in Python, and algorithms and programming in C. Desirable prerequisites include object-oriented analysis and design. The course outline covers: Why Databases? Know Your Course (KYC) KYC: Course Prerequisite KYC: Course Outline KYC: Course Text Book Module Summary The textbook for the course is \"Database System Concepts\" by Abraham Silberschatz, Henry Korth, and S. Sudarshan.","title":"Lecture 1.1 - Course Overview.pdf (PDF file)"},{"location":"week1/Lecture%201.1%20-%20Course%20Overview/#lecture-11-course-overviewpdf-pdf-file","text":"Summary Database Management Systems (DBMSs) are crucial in modern applications, providing organized access to large volumes of interconnected data through a user-friendly interface. They offer advantages such as eliminating data redundancy, enhancing data accessibility, promoting data security, and ensuring data integrity. This course provides an overview of DBMS concepts and applications, including fundamental sets, relations, functions, propositional and predicate logic, data structures, object-oriented analysis, and Python programming. The essential prerequisites for the course include set theory, relations and functions, propositional logic, predicate logic, data structures, programming in Python, and algorithms and programming in C. Desirable prerequisites include object-oriented analysis and design. The course outline covers: Why Databases? Know Your Course (KYC) KYC: Course Prerequisite KYC: Course Outline KYC: Course Text Book Module Summary The textbook for the course is \"Database System Concepts\" by Abraham Silberschatz, Henry Korth, and S. Sudarshan.","title":"Lecture 1.1 - Course Overview.pdf (PDF file)"},{"location":"week1/Lecture%201.2%20-%20Why%20DBMS1/","text":"Lecture 1.2 - Why DBMS1.pdf (PDF file) Summary Module 2 of the course focuses on the evolution of data management and the history of database management systems (DBMSs). It highlights the need for DBMSs from a historical perspective, tracing the evolution of data management practices. The module covers the history of DBMSs, starting with physical data management (book keeping) using ledgers and journals. It discusses the significant advancement in 1886 when Henry Brown patented a device for storing and preserving papers. The invention of punch cards by Herman Hollerith in 1890 for use in tabulating machines further propelled electronic data management. The module explores key parameters for electronic data management, including durability, scalability, security, ease of use, consistency, efficiency, cost, and others. It examines the limitations of traditional file systems in meeting growing data needs and discusses the transition to DBMSs. The module reviews the history of DBMSs, starting with the use of magnetic tapes in the 1950s and early 1960s. It highlights the development of hard disks in the late 1960s and 1970s, enabling direct access to data. The introduction of the relational data model by Ted Codd and the development of commercial relational database systems in the 1980s are also mentioned. The module concludes with a summary of the evolution of data models, DB technology, and DB architecture. Data Management Storage Retrieval Transaction Audit Archival for : individual Small/ big enterprise global Major Approach: Physical also know as Book keeping Electronic Electronic Data or Records management depends on various parameters including: \u2022 Durability \u2022 Scalability \u2022 Security \u2022 Retrieval \u2022 Ease of Use \u2022 Consistency \u2022 Efficiency \u2022 Cost Problems with such an approach of book-keeping: \u2022 Durability: Physical damage to these registers is a possibility due to rodents, humidity, wear and tear \u2022 Scalability: Very difficult to maintain for many years, some shops have numerous registers spanning over years \u2022 Security: Susceptible to tampering by outsiders \u2022 Retrieval: Time consuming process to search for a previous entry \u2022 Consistency: Prone to human errors Spreadsheet files - a better solutionm to natural file creation","title":"Lecture 1.2 - Why DBMS1.pdf (PDF file)"},{"location":"week1/Lecture%201.2%20-%20Why%20DBMS1/#lecture-12-why-dbms1pdf-pdf-file","text":"Summary Module 2 of the course focuses on the evolution of data management and the history of database management systems (DBMSs). It highlights the need for DBMSs from a historical perspective, tracing the evolution of data management practices. The module covers the history of DBMSs, starting with physical data management (book keeping) using ledgers and journals. It discusses the significant advancement in 1886 when Henry Brown patented a device for storing and preserving papers. The invention of punch cards by Herman Hollerith in 1890 for use in tabulating machines further propelled electronic data management. The module explores key parameters for electronic data management, including durability, scalability, security, ease of use, consistency, efficiency, cost, and others. It examines the limitations of traditional file systems in meeting growing data needs and discusses the transition to DBMSs. The module reviews the history of DBMSs, starting with the use of magnetic tapes in the 1950s and early 1960s. It highlights the development of hard disks in the late 1960s and 1970s, enabling direct access to data. The introduction of the relational data model by Ted Codd and the development of commercial relational database systems in the 1980s are also mentioned. The module concludes with a summary of the evolution of data models, DB technology, and DB architecture. Data Management Storage Retrieval Transaction Audit Archival for : individual Small/ big enterprise global Major Approach: Physical also know as Book keeping Electronic Electronic Data or Records management depends on various parameters including: \u2022 Durability \u2022 Scalability \u2022 Security \u2022 Retrieval \u2022 Ease of Use \u2022 Consistency \u2022 Efficiency \u2022 Cost Problems with such an approach of book-keeping: \u2022 Durability: Physical damage to these registers is a possibility due to rodents, humidity, wear and tear \u2022 Scalability: Very difficult to maintain for many years, some shops have numerous registers spanning over years \u2022 Security: Susceptible to tampering by outsiders \u2022 Retrieval: Time consuming process to search for a previous entry \u2022 Consistency: Prone to human errors Spreadsheet files - a better solutionm to natural file creation","title":"Lecture 1.2 - Why DBMS1.pdf (PDF file)"},{"location":"week1/Lecture%201.3%20-%20Why%20DBMS2/","text":"Lecture 1.3 - Why DBMS2.pdf (PDF file) Summary This module introduces file systems and database management systems (DBMSs) and compares their features. File Systems vs. Databases File systems are less efficient for data management, especially with increasing data volume and structural changes. DBMSs are scalable and provide built-in mechanisms for data handling. Python vs. SQL Python is easier to implement for file handling, while SQL provides faster execution in milliseconds even for large datasets. Parameterized Comparison Scalability: DBMSs are more scalable in terms of both data volume and structural changes. Time and Efficiency: DBMSs provide faster data processing through built-in mechanisms like indexing. However, for small datasets, the setup time of a DBMS may outweigh its advantages. Persistence, Robustness, and Security: DBMSs ensure automatic data persistence, provide mechanisms for backup and recovery, and offer user-specific security. Programmer's Productivity: DBMSs reduce coding effort by providing built-in mechanisms for data consistency and relationship maintenance. Arithmetic Operations: Python offers extensive arithmetic and logical operations, while SQL has limited support for these. Costs and Complexity: File systems are less expensive to implement and maintain, while DBMSs require specialized hardware, software, and personnel, leading to higher costs.","title":"Lecture 1.3 - Why DBMS2.pdf (PDF file)"},{"location":"week1/Lecture%201.3%20-%20Why%20DBMS2/#lecture-13-why-dbms2pdf-pdf-file","text":"Summary This module introduces file systems and database management systems (DBMSs) and compares their features. File Systems vs. Databases File systems are less efficient for data management, especially with increasing data volume and structural changes. DBMSs are scalable and provide built-in mechanisms for data handling. Python vs. SQL Python is easier to implement for file handling, while SQL provides faster execution in milliseconds even for large datasets. Parameterized Comparison Scalability: DBMSs are more scalable in terms of both data volume and structural changes. Time and Efficiency: DBMSs provide faster data processing through built-in mechanisms like indexing. However, for small datasets, the setup time of a DBMS may outweigh its advantages. Persistence, Robustness, and Security: DBMSs ensure automatic data persistence, provide mechanisms for backup and recovery, and offer user-specific security. Programmer's Productivity: DBMSs reduce coding effort by providing built-in mechanisms for data consistency and relationship maintenance. Arithmetic Operations: Python offers extensive arithmetic and logical operations, while SQL has limited support for these. Costs and Complexity: File systems are less expensive to implement and maintain, while DBMSs require specialized hardware, software, and personnel, leading to higher costs.","title":"Lecture 1.3 - Why DBMS2.pdf (PDF file)"},{"location":"week1/Lecture%201.4%20-%20Intro%20to%20DBMS1/","text":"Lecture 1.4 - Intro to DBMS1.pdf (PDF file) Summary This document provides an introduction to Database Management Systems (DBMS) by discussing various concepts and components. Levels of Abstraction: Physical level: Database storage and organization. Logical level: Data representation and relationships.= type instructor = record ID : string; name : string; dept name : string; salary : integer; end; View level: Application-specific data presentation and security. Schema and Instance: Schema: Logical structure of the database, specifying data types, constraints, and relationships. logical schema - Analogous to type information of a variable in a program. Physical schema - The overall physical structure of the database. Instance: Actual data stored in the database at a specific time. Data Models: Tools for describing data, relationships, semantics, and constraints. Relational model: Stores data in tables, with rows representing records and columns representing attributes. DDL and DML: Data Definition Language (DDL): Used to create, modify, and delete database structures (e.g., tables). Data Manipulation Language (DML): Used to access and manipulate data (e.g., insert, update, delete). SQL (Structured Query Language): Commercial DML widely used in database systems. Not Turing-machine equivalent, but often embedded in other programming languages. Database Design: Process of creating the database schema and physical layout. Logical design: Deciding on the schema, including attributes and relationships. Physical design: Determining the physical storage and optimization strategies.","title":"Lecture 1.4 - Intro to DBMS1.pdf (PDF file)"},{"location":"week1/Lecture%201.4%20-%20Intro%20to%20DBMS1/#lecture-14-intro-to-dbms1pdf-pdf-file","text":"Summary This document provides an introduction to Database Management Systems (DBMS) by discussing various concepts and components. Levels of Abstraction: Physical level: Database storage and organization. Logical level: Data representation and relationships.= type instructor = record ID : string; name : string; dept name : string; salary : integer; end; View level: Application-specific data presentation and security. Schema and Instance: Schema: Logical structure of the database, specifying data types, constraints, and relationships. logical schema - Analogous to type information of a variable in a program. Physical schema - The overall physical structure of the database. Instance: Actual data stored in the database at a specific time. Data Models: Tools for describing data, relationships, semantics, and constraints. Relational model: Stores data in tables, with rows representing records and columns representing attributes. DDL and DML: Data Definition Language (DDL): Used to create, modify, and delete database structures (e.g., tables). Data Manipulation Language (DML): Used to access and manipulate data (e.g., insert, update, delete). SQL (Structured Query Language): Commercial DML widely used in database systems. Not Turing-machine equivalent, but often embedded in other programming languages. Database Design: Process of creating the database schema and physical layout. Logical design: Deciding on the schema, including attributes and relationships. Physical design: Determining the physical storage and optimization strategies.","title":"Lecture 1.4 - Intro to DBMS1.pdf (PDF file)"},{"location":"week1/Lecture%201.5%20-%20Intro%20to%20DBMS2/","text":"Lecture 1.5 - Intro to DBMS2.pdf (PDF file) Summary Module Overview This module provides an introduction to Database Management Systems (DBMS). Objectives Understand models of DBMS Learn about key components of a database engine Familiarize with database internals and architecture Topics Database Design: Logical design (schema design) Physical design (data layout) Design methodologies (Entity-Relationship Model, Normalization Theory) Object-Relational Data Models: Extension of relational models to include object-oriented concepts Features: complex types, non-atomic values XML: Extensible Markup Language: Overview and uses Data exchange format Database Engine: Storage management: file interaction, data storage/retrieval Query processing: parsing, optimization, evaluation Transaction management: ensuring data integrity and consistency Database System Internals: Database architecture: centralized, client-server, distributed, cloud Database Users and Administrators: Different types of database users and their roles","title":"Lecture 1.5 - Intro to DBMS2.pdf (PDF file)"},{"location":"week1/Lecture%201.5%20-%20Intro%20to%20DBMS2/#lecture-15-intro-to-dbms2pdf-pdf-file","text":"Summary Module Overview This module provides an introduction to Database Management Systems (DBMS). Objectives Understand models of DBMS Learn about key components of a database engine Familiarize with database internals and architecture Topics Database Design: Logical design (schema design) Physical design (data layout) Design methodologies (Entity-Relationship Model, Normalization Theory) Object-Relational Data Models: Extension of relational models to include object-oriented concepts Features: complex types, non-atomic values XML: Extensible Markup Language: Overview and uses Data exchange format Database Engine: Storage management: file interaction, data storage/retrieval Query processing: parsing, optimization, evaluation Transaction management: ensuring data integrity and consistency Database System Internals: Database architecture: centralized, client-server, distributed, cloud Database Users and Administrators: Different types of database users and their roles","title":"Lecture 1.5 - Intro to DBMS2.pdf (PDF file)"},{"location":"week1/check_list/","text":"[X] Text Book [X] slides [X] weekly assigment [X] lecture [ ] live session [ ] text book activity [X] 1.2 [X] 1.3 [X] 1.4 [X] 1.5 [ ] PA [ ] GA","title":"Check list"},{"location":"week1/summary/","text":"Summary The query processor subsystem compiles and executes DDL and DML state- ments. Transaction management ensures that the database remains in a consistent (cor- rect) state despite system failures. The transaction manager ensures that concur- rent transaction executions proceed without con\ufb02icts. The architecture of a database system is greatly in\ufb02uenced by the underlying com- puter system on which the database system runs. Database systems can be central- ized, or parallel, involving multiple machines. Distributed databases span multiple geographically separated machines. Database applications are typically broken up into a front-end part that runs at client machines and a part that runs at the backend. In two-tier architectures, the front end directly communicates with a database running at the back end. In three- tier architectures, the back end part is itself broken up into an application server and a database server. There are four di\ufb00erent types of database-system users, di\ufb00erentiated by the way they expect to interact with the system. Di\ufb00erent types of user interfaces have been designed for the di\ufb00erent types of users. Data-analysis techniques attempt to automatically discover rules and patterns from data. The \ufb01eld of data mining combines knowledge-discovery techniques invented by arti\ufb01cial intelligence researchers and statistical analysts with e\ufb03cient imple- mentation techniques that enable them to be used on extremely large databases. Database-management system (DBMS) Database-system applications Online transaction processing Data analytics File-processing systems Data inconsistency Consistency constraints Data abstraction Physical level Logical level View level Instance Schema Physical schema Logical schema Subschema Physical data independence Data models Entity-relationship model Relational data model Semi-structured data model Object-based data model Database languages Data-de\ufb01nition language Data-manipulation language Procedural DML Declarative DML nonprocedural DML Query language Data-de\ufb01nition language Domain Constraints Referential Integrity Authorization Read authorization Insert authorization Update authorization Delete authorization Metadata Application program Database design Conceptual design Normalization Speci\ufb01cation of functional re- quirements Physical-design phase Database Engine Storage manager Authorization and integrity manager Transaction manager File manager Bu\ufb00er manager Data \ufb01les Data dictionary Indices Query processor DDL interpreter DML compiler Query optimization Query evaluation engine Transaction Atomicity Consistency Durability Recovery manager Failure recovery Concurrency-control manager Database Architecture Centralized Parallel Distributed Database Application Architecture Two-tier Three-tier Application server Database administrator (DBA) This chapter has described several major advantages of a database system. What - are two disadvantages? List \ufb01ve ways in which the type declaration system of a language such as Java or C++ di\ufb00ers from the data de\ufb01nition language used in a database. 3 List six major steps that you would take in setting up a database for a particular enterprise. 4Suppose you want to build a video site similar to YouTube. Consider each of the points listed in Section - 2 as disadvantages of keeping data in a \ufb01le-processing system. Discuss the relevance of each of these points to the storage of actual video data, and to metadata about the video, such as title, the user who uploaded it, tags, and which users viewed it. 5Keyword queries used in web search are quite di\ufb00erent from database queries. List key di\ufb00erences between the two, in terms of the way the queries are speci\ufb01ed and in terms of what is the result of a query. List four applications you have used that most likely employed a database system to store persistent data. 7List four signi\ufb01cant di\ufb00erences between a \ufb01le-processing system and a DBMS. 8Explain the concept of physical data independence and its importance in database systems. 9List \ufb01ve responsibilities of a database-management system. For each responsi- bility, explain the problems that would arise if the responsibility were not dis- charged. 10List at least two reasons why database systems support data manipulation using a declarative query language such as SQL, instead of just providing a library of C or C++ functions to carry out data manipulation. 11Assume that two students are trying to register for a course in which there is only one open seat. What component of a database system prevents both students from being given that last seat? 12Explain the di\ufb00erence between two-tier and three-tier application architectures. Which is better suited for web applications? Why? 13List two features developed in the 2000s and that help database systems handle data-analytics workloads. 14Explain why NoSQL systems emerged in the 2000s, and brie\ufb02y contrast their features with traditional database systems. 15Describe at least three tables that might be used to store information in a social- networking system such as Facebook.","title":"Summary"},{"location":"week1/textbook/","text":"","title":"Textbook"},{"location":"week2/Lecture%202.1%20-%20Introduction%20to%20Relational%20Model1/","text":"Lecture 2.1 - Introduction to Relational Model1.pdf (PDF file) Summary This module introduces the relational model for database management systems. It covers: Attributes and Types: * Attributes represent data characteristics and have specific types, such as alphanumeric strings, dates, or numbers. Schema and Instance: * Schema defines the structure of a relation (table) specifying attributes and their types. * Instance is the current state of a relation, represented as a table with rows (tuples). Keys: * A superkey uniquely identifies tuples in a relation. * A candidate key is a minimal superkey. * A primary key is the selected candidate key used for unique identification. Relational Query Languages: * Relational algebra, a procedural language, is introduced as a tool for manipulating relations using basic operations. * Other \"pure\" languages exist but are not covered here. Lec file Lecture 2.1 - Introduction to Relational Model1.pdf (PDF file)","title":"Lecture 2.1 - Introduction to Relational Model1.pdf (PDF file)"},{"location":"week2/Lecture%202.1%20-%20Introduction%20to%20Relational%20Model1/#lecture-21-introduction-to-relational-model1pdf-pdf-file","text":"Summary This module introduces the relational model for database management systems. It covers: Attributes and Types: * Attributes represent data characteristics and have specific types, such as alphanumeric strings, dates, or numbers. Schema and Instance: * Schema defines the structure of a relation (table) specifying attributes and their types. * Instance is the current state of a relation, represented as a table with rows (tuples). Keys: * A superkey uniquely identifies tuples in a relation. * A candidate key is a minimal superkey. * A primary key is the selected candidate key used for unique identification. Relational Query Languages: * Relational algebra, a procedural language, is introduced as a tool for manipulating relations using basic operations. * Other \"pure\" languages exist but are not covered here. Lec file","title":"Lecture 2.1 - Introduction to Relational Model1.pdf (PDF file)"},{"location":"week2/Lecture%202.1%20-%20Introduction%20to%20Relational%20Model1/#lecture-21-introduction-to-relational-model1pdf-pdf-file_1","text":"","title":"Lecture 2.1 - Introduction to Relational Model1.pdf (PDF file)"},{"location":"week2/Lecture%202.2%20-%20Introduction%20to%20Relational%20Model2/","text":"Lecture 2.2 - Introduction to Relational Model2.pdf (PDF file) Summary Module 7 of Database Management Systems introduces the relational model for data representation and manipulation. It covers relational operators, such as select, project, union, difference, intersection, Cartesian product, and natural join, which allow for the retrieval, combination, and transformation of data in relations. Additionally, aggregation operators, including sum, average, maximum, and minimum, are introduced for performing aggregate calculations. The module emphasizes the properties and limitations of relational languages, including their set-based nature, non-Turing completeness, and the requirement for all data to be present in input tables for output generation. Lec file Lecture 2.2 - Introduction to Relational Model2.pdf (PDF file)","title":"Lecture 2.2 - Introduction to Relational Model2.pdf (PDF file)"},{"location":"week2/Lecture%202.2%20-%20Introduction%20to%20Relational%20Model2/#lecture-22-introduction-to-relational-model2pdf-pdf-file","text":"Summary Module 7 of Database Management Systems introduces the relational model for data representation and manipulation. It covers relational operators, such as select, project, union, difference, intersection, Cartesian product, and natural join, which allow for the retrieval, combination, and transformation of data in relations. Additionally, aggregation operators, including sum, average, maximum, and minimum, are introduced for performing aggregate calculations. The module emphasizes the properties and limitations of relational languages, including their set-based nature, non-Turing completeness, and the requirement for all data to be present in input tables for output generation. Lec file","title":"Lecture 2.2 - Introduction to Relational Model2.pdf (PDF file)"},{"location":"week2/Lecture%202.2%20-%20Introduction%20to%20Relational%20Model2/#lecture-22-introduction-to-relational-model2pdf-pdf-file_1","text":"","title":"Lecture 2.2 - Introduction to Relational Model2.pdf (PDF file)"},{"location":"week2/Lecture%202.3%20-%20Introduction%20to%20SQL1/","text":"Lecture 2.3 - Introduction to SQL1.pdf (PDF file) Summary Module 08: Introduction to SQL Objectives: - Understand relational query language - Understand data definition and basic query structure Outline: - History of SQL - Data Definition Language (DDL) - Data Manipulation Language (DML): Query Structure Data Definition Language (DDL): - Defines information about relations, including: - Schema for each relation - Domain of values associated with each attribute - Integrity constraints - Storage structure on disk Create Table Construct: - create table r (A1D1, A2D2, . . . , AnDn); - r is the relation name - Ai is an attribute name - Di is the data type of values in the domain of Ai Integrity Constraints: - not null : ensures an attribute cannot be null - primary key (A1, . . . , An) : ensures that the values of attributes A1, ..., An uniquely identify each tuple in the relation - foreign key (Am, . . . , An) references r : ensures that the values of attributes Am, ..., An must reference existing values in relation r Data Manipulation Language (DML): Query Structure: - Basic query structure: - select A1, A2, . . . , An - from r1,r2, ...,rm - where P - Where P is a predicate that specifies conditions the result must satisfy Select Clause: - Lists the attributes desired in the result - Can use an asterisk (*) to denote all attributes - Can rename attributes using the as clause Where Clause: - Specifies conditions that tuples in the result must satisfy - Uses logical connectives (and, or, not) to combine conditions From Clause: - Lists the relations involved in the query - Corresponds to the Cartesian product operation in relational algebra Lec file Lecture 2.3 - Introduction to SQL1.pdf (PDF file)","title":"Lecture 2.3 - Introduction to SQL1.pdf (PDF file)"},{"location":"week2/Lecture%202.3%20-%20Introduction%20to%20SQL1/#lecture-23-introduction-to-sql1pdf-pdf-file","text":"Summary Module 08: Introduction to SQL Objectives: - Understand relational query language - Understand data definition and basic query structure Outline: - History of SQL - Data Definition Language (DDL) - Data Manipulation Language (DML): Query Structure Data Definition Language (DDL): - Defines information about relations, including: - Schema for each relation - Domain of values associated with each attribute - Integrity constraints - Storage structure on disk Create Table Construct: - create table r (A1D1, A2D2, . . . , AnDn); - r is the relation name - Ai is an attribute name - Di is the data type of values in the domain of Ai Integrity Constraints: - not null : ensures an attribute cannot be null - primary key (A1, . . . , An) : ensures that the values of attributes A1, ..., An uniquely identify each tuple in the relation - foreign key (Am, . . . , An) references r : ensures that the values of attributes Am, ..., An must reference existing values in relation r Data Manipulation Language (DML): Query Structure: - Basic query structure: - select A1, A2, . . . , An - from r1,r2, ...,rm - where P - Where P is a predicate that specifies conditions the result must satisfy Select Clause: - Lists the attributes desired in the result - Can use an asterisk (*) to denote all attributes - Can rename attributes using the as clause Where Clause: - Specifies conditions that tuples in the result must satisfy - Uses logical connectives (and, or, not) to combine conditions From Clause: - Lists the relations involved in the query - Corresponds to the Cartesian product operation in relational algebra Lec file","title":"Lecture 2.3 - Introduction to SQL1.pdf (PDF file)"},{"location":"week2/Lecture%202.3%20-%20Introduction%20to%20SQL1/#lecture-23-introduction-to-sql1pdf-pdf-file_1","text":"","title":"Lecture 2.3 - Introduction to SQL1.pdf (PDF file)"},{"location":"week2/Lecture%202.4%20-%20Introduction%20to%20SQL2/","text":"Lecture 2.4 - Introduction to SQL2.pdf (PDF file) Summary This module covers the following concepts in SQL: Additional Basic Operations: - Cartesian Product - Rename AS Operation - String Values - Order By Clause - Select Top / Fetch Clause - Where Clause Predicate - Duplicates Examples: - Finding instructors and courses using Cartesian Product and Where Clause - Using Rename AS to rename relations and attributes - Using Like operator for string matching in conditions - Ordering results based on attributes using Order By - Limiting the number of results using Select Top / Fetch - Using In operator to compare multiple values in conditions - Handling duplicates in SQL, where multiset versions of operators are used, resulting in different semantics compared to set-based relational algebra operations. Lec file Lecture 2.4 - Introduction to SQL2.pdf (PDF file)","title":"Lecture 2.4 - Introduction to SQL2.pdf (PDF file)"},{"location":"week2/Lecture%202.4%20-%20Introduction%20to%20SQL2/#lecture-24-introduction-to-sql2pdf-pdf-file","text":"Summary This module covers the following concepts in SQL: Additional Basic Operations: - Cartesian Product - Rename AS Operation - String Values - Order By Clause - Select Top / Fetch Clause - Where Clause Predicate - Duplicates Examples: - Finding instructors and courses using Cartesian Product and Where Clause - Using Rename AS to rename relations and attributes - Using Like operator for string matching in conditions - Ordering results based on attributes using Order By - Limiting the number of results using Select Top / Fetch - Using In operator to compare multiple values in conditions - Handling duplicates in SQL, where multiset versions of operators are used, resulting in different semantics compared to set-based relational algebra operations. Lec file","title":"Lecture 2.4 - Introduction to SQL2.pdf (PDF file)"},{"location":"week2/Lecture%202.4%20-%20Introduction%20to%20SQL2/#lecture-24-introduction-to-sql2pdf-pdf-file_1","text":"","title":"Lecture 2.4 - Introduction to SQL2.pdf (PDF file)"},{"location":"week2/Lecture%202.5%20-%20Introduction%20to%20SQL3/","text":"Lecture 2.5 - Introduction to SQL3.pdf (PDF file) Summary Module 10 of Database Management Systems covers set operations, null values, three-valued logic, aggregate functions, and null values in aggregates. Set Operations: * Union, intersect, and except operators combine sets of rows. * Multiset versions (e.g., union all) retain all duplicates. Null Values: * Unknown or non-existent attribute values. * Arithmetic expressions involving nulls result in null. * Null values are represented as is null or is not null, not with comparison operators. Three-Valued Logic: * Three values: true, false, unknown. * Comparison with nulls returns unknown. * Three-valued logic is applied to OR, AND, and NOT operators. Aggregate Functions: * Operate on rows in a column to return a single value. * Functions include avg, min, max, sum, and count. * Null values are ignored in most aggregate functions. Group By: * Groups rows by selected attributes and computes aggregate functions separately for each group. * Attributes in the select clause must appear in the group by list. Having Clause: * Specifies conditions to filter groups based on aggregate function results. * Applied after group formation. Null Values and Aggregates: * Aggregate functions ignore rows with null values in the aggregated attribute. * Count( ) returns 0 for empty collections and null for null-only collections. Lec file * Lecture 2.5 - Introduction to SQL3.pdf (PDF file)","title":"Lecture 2.5 - Introduction to SQL3.pdf (PDF file)"},{"location":"week2/Lecture%202.5%20-%20Introduction%20to%20SQL3/#lecture-25-introduction-to-sql3pdf-pdf-file","text":"Summary Module 10 of Database Management Systems covers set operations, null values, three-valued logic, aggregate functions, and null values in aggregates. Set Operations: * Union, intersect, and except operators combine sets of rows. * Multiset versions (e.g., union all) retain all duplicates. Null Values: * Unknown or non-existent attribute values. * Arithmetic expressions involving nulls result in null. * Null values are represented as is null or is not null, not with comparison operators. Three-Valued Logic: * Three values: true, false, unknown. * Comparison with nulls returns unknown. * Three-valued logic is applied to OR, AND, and NOT operators. Aggregate Functions: * Operate on rows in a column to return a single value. * Functions include avg, min, max, sum, and count. * Null values are ignored in most aggregate functions. Group By: * Groups rows by selected attributes and computes aggregate functions separately for each group. * Attributes in the select clause must appear in the group by list. Having Clause: * Specifies conditions to filter groups based on aggregate function results. * Applied after group formation. Null Values and Aggregates: * Aggregate functions ignore rows with null values in the aggregated attribute. * Count( ) returns 0 for empty collections and null for null-only collections. Lec file *","title":"Lecture 2.5 - Introduction to SQL3.pdf (PDF file)"},{"location":"week2/Lecture%202.5%20-%20Introduction%20to%20SQL3/#lecture-25-introduction-to-sql3pdf-pdf-file_1","text":"","title":"Lecture 2.5 - Introduction to SQL3.pdf (PDF file)"},{"location":"week2/check_list/","text":"[ ] Text Book [ ] slides [ ] weekly assigment [ ] lecture [ ] live session [ ] text book activity","title":"Check list"},{"location":"week2/tutorial_2.1/","text":"","title":"Tutorial 2.1"},{"location":"week3/Lecture%203.1%20-%20SQL%20Examples_annotated/","text":"This document provides examples of SQL queries, including: - Select statements - Cartesian products and the AS operator - WHERE clauses with AND and OR operators - String matching - ORDER BY clauses - IN clauses - Set operations (UNION, INTERSECT, EXCEPT) - Aggregate functions (AVG, MIN, MAX, COUNT, SUM)# Lecture 3.1 - SQL Examples_annotated.pdf (PDF file)","title":"Lecture 3.1   SQL Examples annotated"},{"location":"week3/Lecture%203.2%20-%20Intermediate%20SQL1_annotated/","text":"This module focuses on nested subqueries in SQL and data modification. Nested subqueries are select-from-where expressions embedded within other queries. They can be used for set membership, set comparisons, and set cardinality tests. Data modification involves deleting, inserting, and updating tuples in database tables. Deletion can be done using the DELETE statement, insertion using the INSERT statement, and updates using the UPDATE statement. The CASE statement can be used for conditional updates. Scalar subqueries can be used to update column values based on computations involving other tables.# Lecture 3.2 - Intermediate SQL1_annotated.pdf (PDF file)","title":"Lecture 3.2   Intermediate SQL1 annotated"},{"location":"week3/Lecture%203.3%20-%20Intermediate%20SQL2_annotated/","text":"Lecture 3.3 - Intermediate SQL2_annotated.pdf (PDF file) Summary Module 13: Intermediate SQL Objectives: Learn SQL expressions for joins Learn SQL expressions for views Outline: Join Expressions Cross join Inner join Outer join Left outer join Right outer join Full outer join Views View definition View expansion View update Materialized views Join Expressions: Join operations return a relation by combining two relations based on a matching condition. Types of joins: Cross join: Cartesian product of rows from both tables. Inner join: Only returns rows that match in both tables. Outer join: Preserves unmatched rows using null values. Left outer join: Includes all rows from the left table and unmatched rows from the right table. Right outer join: Includes all rows from the right table and unmatched rows from the left table. Full outer join: Includes all rows from both tables, even if unmatched. Views: Virtual relations that provide a different perspective on the data. Defined using the create view statement as an SQL query. Can be used in queries and other views. Updates to views are translated into updates on the underlying relations. Some Views Cannot Be Updated: Updates to some views may not be translatable into valid updates on the underlying relations, such as views with multiple tables or complex expressions. Materialized Views: Physical tables that store the results of a view query. Provide faster query performance but need to be maintained when the underlying data changes. Lec file Lecture 3.3 - Intermediate SQL2_annotated.pdf (PDF file)","title":"Lecture 3.3 - Intermediate SQL2_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.3%20-%20Intermediate%20SQL2_annotated/#lecture-33-intermediate-sql2_annotatedpdf-pdf-file","text":"Summary Module 13: Intermediate SQL Objectives: Learn SQL expressions for joins Learn SQL expressions for views Outline: Join Expressions Cross join Inner join Outer join Left outer join Right outer join Full outer join Views View definition View expansion View update Materialized views Join Expressions: Join operations return a relation by combining two relations based on a matching condition. Types of joins: Cross join: Cartesian product of rows from both tables. Inner join: Only returns rows that match in both tables. Outer join: Preserves unmatched rows using null values. Left outer join: Includes all rows from the left table and unmatched rows from the right table. Right outer join: Includes all rows from the right table and unmatched rows from the left table. Full outer join: Includes all rows from both tables, even if unmatched. Views: Virtual relations that provide a different perspective on the data. Defined using the create view statement as an SQL query. Can be used in queries and other views. Updates to views are translated into updates on the underlying relations. Some Views Cannot Be Updated: Updates to some views may not be translatable into valid updates on the underlying relations, such as views with multiple tables or complex expressions. Materialized Views: Physical tables that store the results of a view query. Provide faster query performance but need to be maintained when the underlying data changes. Lec file","title":"Lecture 3.3 - Intermediate SQL2_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.3%20-%20Intermediate%20SQL2_annotated/#lecture-33-intermediate-sql2_annotatedpdf-pdf-file_1","text":"","title":"Lecture 3.3 - Intermediate SQL2_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.4%20-%20Intermediate%20SQL3_annotated/","text":"Lecture 3.4 - Intermediate SQL3_annotated.pdf (PDF file) Summary Module 14: Intermediate SQL/3 introduces advanced concepts in SQL, including: Transactions: * A unit of work that is either executed fully or rolled back to a previous state. * Ensure data integrity and consistency. Integrity Constraints: * Ensure data quality and validity. * Types of constraints: * Not null * Primary key * Unique * Check (predicate) Referential Integrity: * Ensures that a value in one table also exists in another table. * Maintains relationships between data in different tables. SQL Data Types and Schemas: * Introduces additional built-in data types, such as dates, times, and intervals. * Explains the use of user-defined types (UDTs), domains, and large objects. Authorization: * Controls access to data and operations. * Includes privileges such as select, insert, update, and delete on tables and views. * Role-based authorization allows for easier management of permissions. Lec file Lecture 3.4 - Intermediate SQL3_annotated.pdf (PDF file)","title":"Lecture 3.4 - Intermediate SQL3_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.4%20-%20Intermediate%20SQL3_annotated/#lecture-34-intermediate-sql3_annotatedpdf-pdf-file","text":"Summary Module 14: Intermediate SQL/3 introduces advanced concepts in SQL, including: Transactions: * A unit of work that is either executed fully or rolled back to a previous state. * Ensure data integrity and consistency. Integrity Constraints: * Ensure data quality and validity. * Types of constraints: * Not null * Primary key * Unique * Check (predicate) Referential Integrity: * Ensures that a value in one table also exists in another table. * Maintains relationships between data in different tables. SQL Data Types and Schemas: * Introduces additional built-in data types, such as dates, times, and intervals. * Explains the use of user-defined types (UDTs), domains, and large objects. Authorization: * Controls access to data and operations. * Includes privileges such as select, insert, update, and delete on tables and views. * Role-based authorization allows for easier management of permissions. Lec file","title":"Lecture 3.4 - Intermediate SQL3_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.4%20-%20Intermediate%20SQL3_annotated/#lecture-34-intermediate-sql3_annotatedpdf-pdf-file_1","text":"","title":"Lecture 3.4 - Intermediate SQL3_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.5%20-%20Advanced%20SQL_annotated/","text":"Lecture 3.5 - Advanced SQL_annotated.pdf (PDF file) Summary Module 15: Advanced SQL Objectives: Familiarize with functions and procedures in SQL Understand triggers and their performance issues Outline: Functions and Procedural Constructs Triggers Functionality vs Performance Summary: Functions and Procedural Constructs SQL supports functions and control flow statements. External language functions can be used for specialized data types. SQL functions are parameterized views. Triggers Triggers define actions executed in response to insert, update, or delete operations. They can enforce data integrity, update other tables, or invoke functions. There are two types of triggers: BEFORE and AFTER. BEFORE triggers can modify values before database changes, while AFTER triggers can perform additional actions. Triggering Events and Actions Triggers can be triggered by inserts, deletes, or updates. Update triggers can be specific to certain attributes. Values before and after an event can be referenced. Performance Issues Triggers can degrade performance, especially with complex code or iterative operations. Cascading triggers (triggers calling triggers) should be avoided. Consider using row-level triggers instead of statement-level triggers for better efficiency. Best Practices for Triggers Use triggers for short, simple operations unrelated to application logic. Avoid triggers for complex validation, business rules, or calculations. Limit the number of triggers and keep their code concise. Be aware of potential performance issues and test triggers thoroughly. Lec file Lecture 3.5 - Advanced SQL_annotated.pdf (PDF file)","title":"Lecture 3.5 - Advanced SQL_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.5%20-%20Advanced%20SQL_annotated/#lecture-35-advanced-sql_annotatedpdf-pdf-file","text":"Summary Module 15: Advanced SQL Objectives: Familiarize with functions and procedures in SQL Understand triggers and their performance issues Outline: Functions and Procedural Constructs Triggers Functionality vs Performance Summary: Functions and Procedural Constructs SQL supports functions and control flow statements. External language functions can be used for specialized data types. SQL functions are parameterized views. Triggers Triggers define actions executed in response to insert, update, or delete operations. They can enforce data integrity, update other tables, or invoke functions. There are two types of triggers: BEFORE and AFTER. BEFORE triggers can modify values before database changes, while AFTER triggers can perform additional actions. Triggering Events and Actions Triggers can be triggered by inserts, deletes, or updates. Update triggers can be specific to certain attributes. Values before and after an event can be referenced. Performance Issues Triggers can degrade performance, especially with complex code or iterative operations. Cascading triggers (triggers calling triggers) should be avoided. Consider using row-level triggers instead of statement-level triggers for better efficiency. Best Practices for Triggers Use triggers for short, simple operations unrelated to application logic. Avoid triggers for complex validation, business rules, or calculations. Limit the number of triggers and keep their code concise. Be aware of potential performance issues and test triggers thoroughly. Lec file","title":"Lecture 3.5 - Advanced SQL_annotated.pdf (PDF file)"},{"location":"week3/Lecture%203.5%20-%20Advanced%20SQL_annotated/#lecture-35-advanced-sql_annotatedpdf-pdf-file_1","text":"","title":"Lecture 3.5 - Advanced SQL_annotated.pdf (PDF file)"},{"location":"week3/tutorial_3_5/","text":"","title":"Tutorial 3 5"},{"location":"week4/Lecture%204.1%20-%20Formal%20Relational%20Query%20Languages1_annotated/","text":"Lecture 4.1 - Formal Relational Query Languages1_annotated.pdf (PDF file) Summary Module 16 of Database Management Systems focuses on formal relational query languages like relational algebra. Relational algebra is an algebra-based language for querying relational databases. It has six basic operators: Select (\u03c3): Filters rows based on a condition. Project (\u03a0): Selects specific columns. Union (\u222a): Combines rows from two compatible relations. Difference (-): Removes rows that are in the second relation but not the first. Intersection (\u2229): Finds rows that are common to both relations. Cartesian Product (x): Combines all rows from one relation with all rows from another. These operators can be used in combination to create complex queries. Additionally, relational algebra includes a rename operation (\u03c1) and a division operation (\u00f7), which is a derived operation. The basic operations and examples of division are explained in detail. The module provides a thorough understanding of relational algebra and its use in formal relational query languages. Lec file Lecture 4.1 - Formal Relational Query Languages1_annotated.pdf (PDF file)","title":"Lecture 4.1 - Formal Relational Query Languages1_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.1%20-%20Formal%20Relational%20Query%20Languages1_annotated/#lecture-41-formal-relational-query-languages1_annotatedpdf-pdf-file","text":"Summary Module 16 of Database Management Systems focuses on formal relational query languages like relational algebra. Relational algebra is an algebra-based language for querying relational databases. It has six basic operators: Select (\u03c3): Filters rows based on a condition. Project (\u03a0): Selects specific columns. Union (\u222a): Combines rows from two compatible relations. Difference (-): Removes rows that are in the second relation but not the first. Intersection (\u2229): Finds rows that are common to both relations. Cartesian Product (x): Combines all rows from one relation with all rows from another. These operators can be used in combination to create complex queries. Additionally, relational algebra includes a rename operation (\u03c1) and a division operation (\u00f7), which is a derived operation. The basic operations and examples of division are explained in detail. The module provides a thorough understanding of relational algebra and its use in formal relational query languages. Lec file","title":"Lecture 4.1 - Formal Relational Query Languages1_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.1%20-%20Formal%20Relational%20Query%20Languages1_annotated/#lecture-41-formal-relational-query-languages1_annotatedpdf-pdf-file_1","text":"","title":"Lecture 4.1 - Formal Relational Query Languages1_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.2%20-%20Formal%20Relational%20Query%20Languages2_annotated/","text":"Lecture 4.2 - Formal Relational Query Languages2_annotated.pdf (PDF file) Summary This module covers formal calculus-based query languages, including the study of relational algebra, tuple relational calculus, and domain relational calculus. Predicate logic is introduced as the foundation for these calculus-based query languages. Key concepts include: Predicate Logic: A way of expressing statements that cannot be adequately represented by propositional logic. Uses predicates and quantifiers to describe properties and relationships between objects. Tuple Relational Calculus (TRC): A non-procedural query language where queries are expressed as sets of tuples satisfying certain conditions. Uses quantifiers and predicates to define the desired tuples. Domain Relational Calculus (DRC): Equivalent in power to TRC, but uses domain variables instead of tuples. Formulas in DRC resemble predicate calculus formulas. The text also establishes the equivalence of relational algebra, TRC, and DRC, highlighting their equal expressive power. The concept of safe expressions is introduced to prevent infinite relations from being generated in TRC and DRC expressions. Lec file Lecture 4.2 - Formal Relational Query Languages2_annotated.pdf (PDF file)","title":"Lecture 4.2 - Formal Relational Query Languages2_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.2%20-%20Formal%20Relational%20Query%20Languages2_annotated/#lecture-42-formal-relational-query-languages2_annotatedpdf-pdf-file","text":"Summary This module covers formal calculus-based query languages, including the study of relational algebra, tuple relational calculus, and domain relational calculus. Predicate logic is introduced as the foundation for these calculus-based query languages. Key concepts include: Predicate Logic: A way of expressing statements that cannot be adequately represented by propositional logic. Uses predicates and quantifiers to describe properties and relationships between objects. Tuple Relational Calculus (TRC): A non-procedural query language where queries are expressed as sets of tuples satisfying certain conditions. Uses quantifiers and predicates to define the desired tuples. Domain Relational Calculus (DRC): Equivalent in power to TRC, but uses domain variables instead of tuples. Formulas in DRC resemble predicate calculus formulas. The text also establishes the equivalence of relational algebra, TRC, and DRC, highlighting their equal expressive power. The concept of safe expressions is introduced to prevent infinite relations from being generated in TRC and DRC expressions. Lec file","title":"Lecture 4.2 - Formal Relational Query Languages2_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.2%20-%20Formal%20Relational%20Query%20Languages2_annotated/#lecture-42-formal-relational-query-languages2_annotatedpdf-pdf-file_1","text":"","title":"Lecture 4.2 - Formal Relational Query Languages2_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.3%20-%20Entity-Relationship%20Model1_annotated/","text":"Lecture 4.3 - Entity-Relationship Model1_annotated.pdf (PDF file) Summary Database Design Process: Requirement Analysis: Define data needs and business requirements Database Designing: Create an abstraction using a modeling framework Logical Model: Determine database schema Physical Model: Plan database layout Entity-Relationship (ER) Model: Represents an enterprise as a collection of entities, attributes, and relationships Attributes: Properties of entities Entity Sets: Collections of entities of the same type Relationships: Associations among multiple entities Entity Sets: Entities are objects distinguishable from others (e.g., person, company) Entity sets contain entities with shared properties Primary keys uniquely identify members of an entity set Relationships: Associations between entities (e.g., student-advisor relationship) Relationship sets define mathematical relations between multiple entities Mapping Cardinality Constraints: Expresses the number of entities that can be associated via a relationship Types: One to one One to many Many to one Many to many Weak Entity Sets: Entity sets that lack sufficient attributes for unique identification Dependent on strong entity sets through an identifying relationship Primary key of weak entity set = Discriminator + Primary Key of strong entity set Lec file Lecture 4.3 - Entity-Relationship Model1_annotated.pdf (PDF file)","title":"Lecture 4.3 - Entity-Relationship Model1_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.3%20-%20Entity-Relationship%20Model1_annotated/#lecture-43-entity-relationship-model1_annotatedpdf-pdf-file","text":"Summary Database Design Process: Requirement Analysis: Define data needs and business requirements Database Designing: Create an abstraction using a modeling framework Logical Model: Determine database schema Physical Model: Plan database layout Entity-Relationship (ER) Model: Represents an enterprise as a collection of entities, attributes, and relationships Attributes: Properties of entities Entity Sets: Collections of entities of the same type Relationships: Associations among multiple entities Entity Sets: Entities are objects distinguishable from others (e.g., person, company) Entity sets contain entities with shared properties Primary keys uniquely identify members of an entity set Relationships: Associations between entities (e.g., student-advisor relationship) Relationship sets define mathematical relations between multiple entities Mapping Cardinality Constraints: Expresses the number of entities that can be associated via a relationship Types: One to one One to many Many to one Many to many Weak Entity Sets: Entity sets that lack sufficient attributes for unique identification Dependent on strong entity sets through an identifying relationship Primary key of weak entity set = Discriminator + Primary Key of strong entity set Lec file","title":"Lecture 4.3 - Entity-Relationship Model1_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.3%20-%20Entity-Relationship%20Model1_annotated/#lecture-43-entity-relationship-model1_annotatedpdf-pdf-file_1","text":"","title":"Lecture 4.3 - Entity-Relationship Model1_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.4%20-%20Entity-Relationship%20Model2_annotated/","text":"Lecture 4.4 - Entity-Relationship Model2_annotated.pdf (PDF file) Summary Entity-Relationship (ER) Diagram Components: Entity Sets: Represent real-world entities (e.g., Student, Course). Relationship Sets: Represent relationships between entities (e.g., Advisor). ERD Notation: Rectangles: Entity sets Diamonds: Relationship sets Underlining: Primary key attributes Roles: Labels on lines connecting entities to relationship sets Minimum and maximum cardinality constraints: l..h (e.g., 1..*, 0..1) Total participation: Double line Partial participation: Single line Entity Sets: Strong entity sets: Every entity must participate in the set. Weak entity sets: Entities dependent on another entity set (identifying entity set). Relationship Sets: One-to-one: Each entity in one set relates to exactly one entity in the other set. Many-to-one: Each entity in one set relates to multiple entities in the other set. Many-to-many: Entities in both sets relate to multiple entities in the other set. ER Model to Relational Schema Translation: Entity sets are represented by tables with the same attributes. Relationship sets are represented by tables with the primary keys of the participating entity sets. Complex attributes are flattened into separate attributes. Multivalued attributes are represented by a separate table. Redundancy in Schema: Many-to-one/one-to-many relationships can be represented by adding an attribute to the \"many\" side instead of creating a separate schema. Weak entity sets are redundant and can be represented by the identifying entity set. Lec file Lecture 4.4 - Entity-Relationship Model2_annotated.pdf (PDF file)","title":"Lecture 4.4 - Entity-Relationship Model2_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.4%20-%20Entity-Relationship%20Model2_annotated/#lecture-44-entity-relationship-model2_annotatedpdf-pdf-file","text":"Summary Entity-Relationship (ER) Diagram Components: Entity Sets: Represent real-world entities (e.g., Student, Course). Relationship Sets: Represent relationships between entities (e.g., Advisor). ERD Notation: Rectangles: Entity sets Diamonds: Relationship sets Underlining: Primary key attributes Roles: Labels on lines connecting entities to relationship sets Minimum and maximum cardinality constraints: l..h (e.g., 1..*, 0..1) Total participation: Double line Partial participation: Single line Entity Sets: Strong entity sets: Every entity must participate in the set. Weak entity sets: Entities dependent on another entity set (identifying entity set). Relationship Sets: One-to-one: Each entity in one set relates to exactly one entity in the other set. Many-to-one: Each entity in one set relates to multiple entities in the other set. Many-to-many: Entities in both sets relate to multiple entities in the other set. ER Model to Relational Schema Translation: Entity sets are represented by tables with the same attributes. Relationship sets are represented by tables with the primary keys of the participating entity sets. Complex attributes are flattened into separate attributes. Multivalued attributes are represented by a separate table. Redundancy in Schema: Many-to-one/one-to-many relationships can be represented by adding an attribute to the \"many\" side instead of creating a separate schema. Weak entity sets are redundant and can be represented by the identifying entity set. Lec file","title":"Lecture 4.4 - Entity-Relationship Model2_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.4%20-%20Entity-Relationship%20Model2_annotated/#lecture-44-entity-relationship-model2_annotatedpdf-pdf-file_1","text":"","title":"Lecture 4.4 - Entity-Relationship Model2_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.5%20-%20Entity-Relationship%20Model3_annotated/","text":"Lecture 4.5 - Entity-Relationship Model3_annotated.pdf (PDF file) Summary Extended Features of the Entity-Relationship Model Non-binary relationships: These relationships involve more than two entities. Specialization: A sub-group of entities within an entity set is designated with distinctive characteristics. These sub-groups become lower-level entity sets that inherit attributes and relationships from the higher-level entity set. Generalization: Combining a number of entity sets with shared features into a higher-level entity set. Aggregation: Treating a relationship set as an abstract entity, allowing for relationships between relationships. Design Issues Entities vs. Attributes: Deciding whether to represent an object as an entity or an attribute. Entities vs. Relationship Sets: Distinguishing between real-world concepts that are best expressed by entities or relationships. Binary vs. Non-Binary Relationships: Determining whether to use binary or non-binary relationships to represent a relationship. Strong vs. Weak Entity Sets: Strong entity sets have an independent existence, while weak entity sets exist only in conjunction with another entity set. Specialization/Generalization: Using specialization to divide an entity set into sub-groups or generalization to combine entity sets with shared features. Aggregation: Treating an aggregate entity set as a unit without considering its internal structure. ER Notation Symbols for representing entities, relationships, and attributes in an ER diagram. Diagrams provide a graphical representation of the relationships and constraints between entities in a database. Lec file Lecture 4.5 - Entity-Relationship Model3_annotated.pdf (PDF file)","title":"Lecture 4.5 - Entity-Relationship Model3_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.5%20-%20Entity-Relationship%20Model3_annotated/#lecture-45-entity-relationship-model3_annotatedpdf-pdf-file","text":"Summary Extended Features of the Entity-Relationship Model Non-binary relationships: These relationships involve more than two entities. Specialization: A sub-group of entities within an entity set is designated with distinctive characteristics. These sub-groups become lower-level entity sets that inherit attributes and relationships from the higher-level entity set. Generalization: Combining a number of entity sets with shared features into a higher-level entity set. Aggregation: Treating a relationship set as an abstract entity, allowing for relationships between relationships. Design Issues Entities vs. Attributes: Deciding whether to represent an object as an entity or an attribute. Entities vs. Relationship Sets: Distinguishing between real-world concepts that are best expressed by entities or relationships. Binary vs. Non-Binary Relationships: Determining whether to use binary or non-binary relationships to represent a relationship. Strong vs. Weak Entity Sets: Strong entity sets have an independent existence, while weak entity sets exist only in conjunction with another entity set. Specialization/Generalization: Using specialization to divide an entity set into sub-groups or generalization to combine entity sets with shared features. Aggregation: Treating an aggregate entity set as a unit without considering its internal structure. ER Notation Symbols for representing entities, relationships, and attributes in an ER diagram. Diagrams provide a graphical representation of the relationships and constraints between entities in a database. Lec file","title":"Lecture 4.5 - Entity-Relationship Model3_annotated.pdf (PDF file)"},{"location":"week4/Lecture%204.5%20-%20Entity-Relationship%20Model3_annotated/#lecture-45-entity-relationship-model3_annotatedpdf-pdf-file_1","text":"","title":"Lecture 4.5 - Entity-Relationship Model3_annotated.pdf (PDF file)"}]}